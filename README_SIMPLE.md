# ğŸ—ºï¸ Google Maps Scraper Simple

Version simplifiÃ©e du scraper Google Maps qui permet de scraper des entreprises dans plusieurs villes et d'exporter les rÃ©sultats en CSV.

## âœ¨ FonctionnalitÃ©s

- âœ… **Multi-villes** : Scrape plusieurs villes en une seule exÃ©cution
- âœ… **Export CSV** : RÃ©sultats exportÃ©s dans un fichier CSV facile Ã  exploiter
- âœ… **Simple** : Aucune configuration complexe (juste un token Apify)
- âœ… **Flexible** : Mode interactif ou ligne de commande avec arguments
- âœ… **Chargement depuis fichier** : Importez une liste de villes depuis un fichier texte

## ğŸ“‹ PrÃ©requis

1. **Python 3.7+**
2. **Compte Apify** (gratuit) : [https://console.apify.com/](https://console.apify.com/)
   - CrÃ©ez un compte gratuit
   - RÃ©cupÃ©rez votre token API dans `Account > Integrations`

## ğŸš€ Installation

### 1. Cloner le dÃ©pÃ´t

```bash
git clone <votre-repo>
cd google-maps-scraper
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements_simple.txt
```

### 3. Configurer le token Apify

Copiez le fichier d'exemple et ajoutez votre token :

```bash
cp .env.simple.example .env
```

Ã‰ditez `.env` et remplacez `your_apify_token_here` par votre vrai token Apify :

```env
APIFY_API_TOKEN=apify_api_XXXXXXXXXXXXXXXXXXXXXXXXXX
```

## ğŸ“– Utilisation

### Mode 1 : Mode Interactif (RecommandÃ© pour dÃ©buter)

Lancez simplement le script sans arguments :

```bash
python run_scraper.py
```

Le script vous guidera Ã©tape par Ã©tape :
1. Terme de recherche (ex: "restaurants", "menuisiers")
2. Liste des villes (manuellement ou depuis un fichier)
3. Nombre de rÃ©sultats par ville
4. Nom du fichier de sortie (optionnel)

### Mode 2 : Ligne de Commande

#### Exemple basique avec villes en ligne

```bash
python run_scraper.py -s "restaurants" -c "Paris,Lyon,Marseille" -m 100
```

#### Exemple avec fichier de villes

```bash
python run_scraper.py -s "menuisiers" -f villes_exemple.txt -m 50
```

#### Exemple avec sortie personnalisÃ©e

```bash
python run_scraper.py -s "plombiers" -c "Paris,Lyon" -o mes_plombiers.csv -m 75
```

### Mode 3 : Import Python

Vous pouvez Ã©galement utiliser le scraper dans vos propres scripts Python :

```python
from scraper_simple import GoogleMapsScraperSimple

# CrÃ©er le scraper
scraper = GoogleMapsScraperSimple()

# DÃ©finir les paramÃ¨tres
search_term = "restaurants"
cities = ["Paris", "Lyon", "Marseille"]
max_results_per_city = 50

# ExÃ©cuter le scraping
results, csv_file = scraper.run(search_term, cities, max_results_per_city)

print(f"âœ… {len(results)} entreprises scrapÃ©es")
print(f"ğŸ’¾ RÃ©sultats dans: {csv_file}")
```

## ğŸ“Š Options de la Ligne de Commande

```
Options:
  -s, --search TERME          Terme de recherche (ex: "restaurants")
  -c, --cities VILLES         Villes sÃ©parÃ©es par virgules (ex: "Paris,Lyon")
  -f, --file FICHIER          Fichier texte avec une ville par ligne
  -m, --max-results NOMBRE    Max rÃ©sultats par ville (dÃ©faut: 50)
  -o, --output FICHIER        Nom du fichier CSV de sortie (optionnel)
  -t, --token TOKEN           Token Apify (optionnel, lu depuis .env)
  -h, --help                  Afficher l'aide
```

## ğŸ“ Format du Fichier de Villes

CrÃ©ez un fichier texte (`.txt`) avec une ville par ligne :

```
Paris
Lyon
Marseille
Toulouse
Nice
```

Exemple fourni : `villes_exemple.txt`

## ğŸ“¤ Format du Fichier CSV de Sortie

Le fichier CSV contient les colonnes suivantes :

| Colonne | Description |
|---------|-------------|
| **Nom** | Nom de l'entreprise |
| **Adresse** | Adresse complÃ¨te |
| **TÃ©lÃ©phone** | NumÃ©ro de tÃ©lÃ©phone |
| **Site Web** | URL du site web |
| **Note** | Note Google Maps (0-5) |
| **Nombre Avis** | Nombre d'avis |
| **CatÃ©gorie** | CatÃ©gorie de l'entreprise |
| **Ville de recherche** | Ville utilisÃ©e pour la recherche |
| **Terme de recherche** | Terme utilisÃ© pour la recherche |
| **URL Google Maps** | Lien vers la page Google Maps |
| **Latitude** | CoordonnÃ©e GPS |
| **Longitude** | CoordonnÃ©e GPS |
| **Plus Code** | Code Plus Google |
| **Horaires** | Horaires d'ouverture |
| **Description** | Description de l'entreprise |

## ğŸ’¡ Exemples d'Utilisation

### Exemple 1 : Trouver des restaurants dans 3 villes

```bash
python run_scraper.py -s "restaurants italiens" -c "Paris,Lyon,Nice" -m 100
```

**RÃ©sultat** : Jusqu'Ã  300 restaurants italiens (100 par ville) exportÃ©s en CSV

### Exemple 2 : Trouver des artisans dans toutes les grandes villes

CrÃ©ez `grandes_villes.txt` :
```
Paris
Lyon
Marseille
Toulouse
Nice
Nantes
Strasbourg
Montpellier
Bordeaux
Lille
```

Puis exÃ©cutez :
```bash
python run_scraper.py -s "menuisiers" -f grandes_villes.txt -m 50 -o menuisiers_france.csv
```

**RÃ©sultat** : Jusqu'Ã  500 menuisiers (50 par ville Ã— 10 villes)

### Exemple 3 : Scraping massif avec Python

```python
from scraper_simple import GoogleMapsScraperSimple

scraper = GoogleMapsScraperSimple()

# Charger les villes depuis un fichier
with open('grandes_villes.txt', 'r') as f:
    cities = [line.strip() for line in f]

# Scraper plusieurs types d'entreprises
search_terms = ["plombiers", "Ã©lectriciens", "menuisiers"]

for term in search_terms:
    print(f"\nğŸ” Scraping: {term}")
    results, csv_file = scraper.run(term, cities, max_results_per_city=50)
    print(f"âœ… {csv_file} crÃ©Ã© avec {len(results)} rÃ©sultats")
```

## âš™ï¸ Architecture SimplifiÃ©e

```
google-maps-scraper/
â”‚
â”œâ”€â”€ scraper_simple.py          # Classe principale du scraper
â”œâ”€â”€ run_scraper.py             # Script CLI pour exÃ©cuter le scraper
â”œâ”€â”€ requirements_simple.txt    # DÃ©pendances minimales
â”œâ”€â”€ .env.simple.example        # Template de configuration
â”œâ”€â”€ villes_exemple.txt         # Liste d'exemple de villes
â””â”€â”€ README_SIMPLE.md          # Cette documentation
```

## ğŸ”§ DÃ©pendances

Seulement 2 dÃ©pendances Python :

- `apify-client` : Client officiel Apify pour le scraping
- `python-dotenv` : Gestion des variables d'environnement

## âš¡ Performance

- **Temps moyen par ville** : 30-60 secondes
- **Limite Apify gratuit** : ~500 rÃ©sultats/mois (varie selon le plan)
- **Pause entre requÃªtes** : 2 secondes (Ã©vite le rate limiting)

## ğŸ†š DiffÃ©rences avec la Version ComplÃ¨te

| FonctionnalitÃ© | Version Simple | Version ComplÃ¨te |
|---------------|----------------|------------------|
| Scraping Google Maps | âœ… | âœ… |
| Multi-villes | âœ… | âŒ |
| Export CSV | âœ… | âŒ |
| Export Google Sheets | âŒ | âœ… |
| Recherche d'emails | âŒ | âœ… |
| Enrichissement contacts | âŒ | âœ… |
| Scoring qualitÃ© | âŒ | âœ… |
| API SIRET | âŒ | âœ… |
| GoHighLevel CRM | âŒ | âœ… |

**â¡ï¸ Utilisez la version simple si** : Vous voulez juste scraper des entreprises dans plusieurs villes et obtenir un CSV

**â¡ï¸ Utilisez la version complÃ¨te si** : Vous faites de la prospection B2B et avez besoin d'emails + enrichissement

## ğŸ› DÃ©pannage

### Erreur "APIFY_API_TOKEN manquant"

**Solution** : VÃ©rifiez que le fichier `.env` existe et contient votre token Apify valide

### Erreur "Rate limit exceeded"

**Solution** : Le scraper intÃ¨gre dÃ©jÃ  des pauses. Si le problÃ¨me persiste, augmentez la pause dans `scraper_simple.py` ligne 127 (actuellement 2 secondes)

### Trop peu de rÃ©sultats

**Solution** :
- VÃ©rifiez votre requÃªte de recherche (soyez plus gÃ©nÃ©rique)
- Augmentez `-m` (max rÃ©sultats par ville)
- Certaines villes peuvent avoir moins d'entreprises que d'autres

### Fichier CSV vide

**Solution** :
- VÃ©rifiez que le scraping n'a pas retournÃ© 0 rÃ©sultats
- VÃ©rifiez les permissions d'Ã©criture du dossier
- Consultez les logs pour identifier l'erreur

## ğŸ“ Support

Pour toute question ou bug :
1. Consultez d'abord cette documentation
2. VÃ©rifiez les logs d'erreur affichÃ©s
3. Ouvrez une issue sur GitHub

## ğŸ“„ Licence

Ce projet est fourni tel quel, sans garantie. Utilisez-le de maniÃ¨re responsable et respectez les conditions d'utilisation de Google Maps et Apify.

## ğŸ¯ Roadmap Future

- [ ] Support du format JSON en sortie
- [ ] Filtrage par note minimum
- [ ] DÃ©tection et suppression des doublons
- [ ] Mode "append" pour ajouter Ã  un CSV existant
- [ ] Barre de progression visuelle

---

**Bon scraping ! ğŸš€**
